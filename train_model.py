import os
import numpy as np
import pandas as pd
import joblib
import librosa
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from feature_extractor import extract_feature

# ==========================
# 1ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ã‚¹è¨­å®š
# ==========================
DATASET_DIR = "dataset"
WAV_DIR = os.path.join(DATASET_DIR, "wav")
TRANS_DIR = os.path.join(DATASET_DIR, "trans")
EVAL_DIR = os.path.join(DATASET_DIR, "eval")

CATEGORY_FILE = os.path.join(EVAL_DIR, "category.txt")

# ==========================
# 2ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
# ==========================
def load_dataset():
    """
    dataset/wav/*.wav ã¨ dataset/eval/category.txt ã‚’å¯¾å¿œã¥ã‘ã¦
    ç‰¹å¾´é‡ã¨æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ã‚’æŠ½å‡º
    """
    df = pd.read_csv(
        CATEGORY_FILE,
        header=None,
        names=["file_id", "utt_id", "emotion1", "emotion2", "emotion3"],
    )

    X, y = [], []

    for _, row in df.iterrows():
        wav_name = f"{row['file_id']}.wav"
        wav_path = os.path.join(WAV_DIR, wav_name)

        if not os.path.exists(wav_path):
            print(f"âš ï¸ {wav_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            continue

        try:
            features = extract_feature(wav_path)
            X.append(features)
            y.append(row["emotion1"])  # ãƒ¡ã‚¤ãƒ³ã®æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«
        except Exception as e:
            print(f"âŒ {wav_name} ã®ç‰¹å¾´æŠ½å‡ºã«å¤±æ•—: {e}")

    return np.array(X), np.array(y)

# ==========================
# 3ï¸âƒ£ ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
# ==========================
def train_model():
    X, y = load_dataset()

    if len(X) == 0:
        raise ValueError("âŒ ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚dataset/ ã®ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    print(f"âœ… èª­ã¿è¾¼ã‚“ã ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X)}")

    # ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)

    # ç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆåˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
    )

    # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
    model = RandomForestClassifier(n_estimators=150, random_state=42)
    model.fit(X_train, y_train)

    # ç²¾åº¦è©•ä¾¡
    acc = model.score(X_test, y_test)
    print(f"ğŸ¯ ãƒ†ã‚¹ãƒˆç²¾åº¦: {acc:.3f}")

    # ==========================
    # 4ï¸âƒ£ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ï¼ˆutils.pyã¨é€£æºï¼‰
    # ==========================
    os.makedirs("model", exist_ok=True)
    joblib.dump(model, "model/classifier.pkl")
    joblib.dump(scaler, "model/scaler.pkl")
    np.save("model/labels.npy", label_encoder.classes_)

    print("âœ… ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼šmodel/classifier.pkl")
    print("âœ… ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼šmodel/scaler.pkl")
    print("âœ… ãƒ©ãƒ™ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼šmodel/labels.npy")

if __name__ == "__main__":
    train_model()
