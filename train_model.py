import os
import numpy as np
import pandas as pd
import librosa
import joblib
from tqdm import tqdm
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier

# ====== è¨­å®š ======
DATASET_CSV = "dataset/transcripts.csv"   # CSV: filename, text, emotion
AUDIO_DIR = "dataset/audio"               # WAVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
MODEL_DIR = "model"                       # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¿å­˜å…ˆ
SAMPLE_RATE = 16000                       # JSUT/ä¸€èˆ¬çš„éŸ³å£°ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ

# ====== ç‰¹å¾´é‡æŠ½å‡ºé–¢æ•° ======
def extract_features(file_path, sr=SAMPLE_RATE, n_mfcc=40):
    try:
        y, sr = librosa.load(file_path, sr=sr)
        # MFCCç‰¹å¾´é‡ã‚’æŠ½å‡º
        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)
        # å„æ¬¡å…ƒã®å¹³å‡ã‚’å–ã‚‹ï¼ˆå›ºå®šé•·ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰
        return np.mean(mfccs.T, axis=0)
    except Exception as e:
        print(f"âš ï¸ {file_path} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# ====== ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿ ======
def load_dataset(csv_path, audio_dir):
    df = pd.read_csv(csv_path)
    features, labels = [], []

    print(f"ğŸ§ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿ä¸­ ({len(df)} ä»¶)...")
    for _, row in tqdm(df.iterrows(), total=len(df)):
        filename = str(row["filename"]).strip()
        emotion = str(row["emotion"]).strip()

        audio_path = os.path.join(audio_dir, filename)
        if not os.path.exists(audio_path):
            print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {audio_path}")
            continue

        feat = extract_features(audio_path)
        if feat is not None:
            features.append(feat)
            labels.append(emotion)

    print(f"âœ… æœ‰åŠ¹ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(features)}")
    return np.array(features), np.array(labels)

# ====== å­¦ç¿’å‡¦ç† ======
def train_and_save_model(X, y):
    print("âš™ï¸ ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–ä¸­...")
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42, stratify=y
    )

    print("ğŸ§  ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­ (RandomForest)...")
    clf = RandomForestClassifier(n_estimators=300, random_state=42)
    clf.fit(X_train, y_train)

    acc = clf.score(X_test, y_test)
    print(f"âœ… ãƒ†ã‚¹ãƒˆç²¾åº¦: {acc:.3f}")

    # ä¿å­˜
    os.makedirs(MODEL_DIR, exist_ok=True)
    joblib.dump(clf, os.path.join(MODEL_DIR, "classifier.pkl"))
    joblib.dump(scaler, os.path.join(MODEL_DIR, "scaler.pkl"))
    np.save(os.path.join(MODEL_DIR, "labels.npy"), np.unique(y))
    print(f"ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº† â†’ {MODEL_DIR}/")

# ====== ãƒ¡ã‚¤ãƒ³ ======
if __name__ == "__main__":
    X, y = load_dataset(DATASET_CSV, AUDIO_DIR)
    if len(X) == 0:
        print("âŒ æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚CSVã‚„ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    else:
        train_and_save_model(X, y)
